{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43334558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import XLNetTokenizer, XLNetLMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aae9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desactivar wandb completamente\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c0b790b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay GPU disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f49430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci칩n de par치metros para generaci칩n de secuencias\n",
    "model_name = \"Rostlab/prot_xlnet\"\n",
    "batch_size = 8  # Reducido para generaci칩n que requiere m치s memoria\n",
    "num_epochs = 3\n",
    "learning_rate = 5e-5\n",
    "max_length = 512\n",
    "output_dir = \"./prot_xlnet_generation_finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5db36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorio de salida si no existe\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466589d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando tokenizador y modelo para generaci칩n de secuencias...\n"
     ]
    }
   ],
   "source": [
    "# Cargar tokenizador y modelo para generaci칩n de lenguaje\n",
    "print(\"Cargando tokenizador y modelo para generaci칩n de secuencias...\")\n",
    "tokenizer = XLNetTokenizer.from_pretrained(model_name)\n",
    "# Usar XLNetLMHeadModel para generaci칩n de texto/secuencias\n",
    "model = XLNetLMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f488d1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario del tokenizador: 37 tokens\n",
      "El modelo est치 configurado para generaci칩n de secuencias de prote칤nas\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulario del tokenizador: {tokenizer.vocab_size} tokens\")\n",
    "print(\"El modelo est치 configurado para generaci칩n de secuencias de prote칤nas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b7f0db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLNetLMHeadModel(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(37, 1024)\n",
       "    (layer): ModuleList(\n",
       "      (0-29): 30 x XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): ReLU()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_loss): Linear(in_features=1024, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mover el modelo al dispositivo adecuado\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fecc8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para congelar las capas base y solo entrenar las nuevas\n",
    "for param in model.transformer.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da424da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci칩n para crear datos de ejemplo (reemplazar con secuencias reales)\n",
    "def create_protein_sequences_data():\n",
    "    \"\"\"\n",
    "    Crea un conjunto de datos de ejemplo de secuencias de prote칤nas.\n",
    "    REEMPLAZA ESTA FUNCI칍N con la carga de tus secuencias reales.\n",
    "    \"\"\"\n",
    "    # Secuencias de ejemplo m치s realistas\n",
    "    sequences = [\n",
    "        \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\",\n",
    "        \"MASNTVSAQGGSNRPVRDLASRQDFVRASSIIEKQLRDKVSADDLPVTLAQHLAVNFLHVLRLLE\",\n",
    "        \"MTMDKSELVQKAKLAEQAERYDDMAAAMKAVTEQGHELSNEERNLLSVAYKNVVGARRSSWRVVSSIEQKTEGAEKKQQ\",\n",
    "        \"MAFSAEDVLKEYDRRRRMEALLLSLYYPNDRKLLDYKEWSPPRVQVECPKAPVEWNNPPSEKGLIVGHFSGIKYKGEKAQASEVDVNKMCCWVSKFKDAMRRYQGIQTCKIPGKVLSDLDAKIKAYNLTVEGVEGFVRYSRVTKQHVAAFLKELRHSKQYENVNLIHYILTDKRVDIQHLEKDLVKDLQAKGIQYLHQKGLKKQVPEGVKVP\",\n",
    "        \"MGDVEKGKKIFIMKCSQCHTVEKGGKHKTGPNLHGLFGRKTGQAPGYSYTAANKNKGIIWGEDTLMEYLENPKKYIPGTKMIFVGIKKKEERADLIAYLKKATNE\"\n",
    "    ]\n",
    "    \n",
    "    # A침adir m치s secuencias simuladas si necesitas m치s datos de prueba\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    for i in range(50):  # Reducido para este ejemplo\n",
    "        seq_length = np.random.randint(80, 300)  # Longitudes m치s realistas\n",
    "        seq = ''.join(np.random.choice(list(amino_acids)) for _ in range(seq_length))\n",
    "        sequences.append(seq)\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b581f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_protein_sequences(file_path=None):\n",
    "    \"\"\"\n",
    "    Funci칩n para cargar tus secuencias reales de prote칤nas.\n",
    "    Adapta esta funci칩n seg칰n el formato de tus datos.\n",
    "    \n",
    "    Formatos soportados:\n",
    "    - CSV con columna 'sequence'\n",
    "    - FASTA\n",
    "    - Texto plano (una secuencia por l칤nea)\n",
    "    \"\"\"\n",
    "    if file_path is None:\n",
    "        print(\"Usando datos de ejemplo. Para usar tus datos reales:\")\n",
    "        print(\"1. Modifica la funci칩n load_real_protein_sequences()\")\n",
    "        print(\"2. O pasa el path a tu archivo de secuencias\")\n",
    "        return create_protein_sequences_data()\n",
    "    \n",
    "    sequences = []\n",
    "    \n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'sequence' in df.columns:\n",
    "            sequences = df['sequence'].tolist()\n",
    "        else:\n",
    "            print(\"El CSV debe tener una columna llamada 'sequence'\")\n",
    "            return create_protein_sequences_data()\n",
    "    \n",
    "    elif file_path.endswith('.fasta') or file_path.endswith('.fa'):\n",
    "        with open(file_path, 'r') as f:\n",
    "            current_seq = \"\"\n",
    "            for line in f:\n",
    "                if line.startswith('>'):\n",
    "                    if current_seq:\n",
    "                        sequences.append(current_seq)\n",
    "                        current_seq = \"\"\n",
    "                else:\n",
    "                    current_seq += line.strip()\n",
    "            if current_seq:\n",
    "                sequences.append(current_seq)\n",
    "    \n",
    "    elif file_path.endswith('.txt'):\n",
    "        with open(file_path, 'r') as f:\n",
    "            sequences = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    print(f\"Cargadas {len(sequences)} secuencias de {file_path}\")\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0fa0fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargadas 6107 secuencias de ../data/raw/peptides_labeled.csv\n",
      "Total de secuencias cargadas: 6107\n",
      "Longitud promedio: 17.3 amino치cidos\n",
      "Rango de longitudes: 2 - 97\n"
     ]
    }
   ],
   "source": [
    "# Cargar secuencias (modifica el path para usar tus datos reales)\n",
    "#sequences = load_real_protein_sequences()  # Cambia por \n",
    "sequences = load_real_protein_sequences(\"../data/raw/peptides_labeled.csv\")\n",
    "\n",
    "print(f\"Total de secuencias cargadas: {len(sequences)}\")\n",
    "print(f\"Longitud promedio: {np.mean([len(seq) for seq in sequences]):.1f} amino치cidos\")\n",
    "print(f\"Rango de longitudes: {min(len(seq) for seq in sequences)} - {max(len(seq) for seq in sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9667526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjuntos de entrenamiento y validaci칩n\n",
    "train_sequences, val_sequences = train_test_split(sequences, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25798212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci칩n para tokenizar las secuencias para generaci칩n\n",
    "def tokenize_for_generation(examples):\n",
    "    \"\"\"\n",
    "    Tokeniza las secuencias para entrenamiento de generaci칩n de lenguaje.\n",
    "    A침ade tokens especiales y prepara para masked language modeling.\n",
    "    \"\"\"\n",
    "    # Tokenizar las secuencias\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"sequence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "        return_special_tokens_mask=True\n",
    "    )\n",
    "    \n",
    "    # Para XLNet, usamos los input_ids como labels tambi칠n (language modeling)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
    "    \n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eae9653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datasets\n",
    "train_dataset = Dataset.from_dict({\"sequence\": train_sequences})\n",
    "val_dataset = Dataset.from_dict({\"sequence\": val_sequences})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc50c773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8da7ba785d49f69905a29c0574f61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4885 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d7a79461c041a2b2ee6f411a8ff59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1222 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizar los datasets\n",
    "train_dataset = train_dataset.map(tokenize_for_generation, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_for_generation, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d614b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el data collator para language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # XLNet usa autoregressive LM, no masked LM\n",
    "    mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdcc305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\TMP_CASES\\DEV\\GIT\\ADVANCE_DRUG_DISCOVERY\\ADVANCED_DRUG_DISCOVERY\\.VENV\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 游뱅 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# Configurar los argumentos de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    gradient_accumulation_steps=4,  # Aumentado para compensar batch size menor\n",
    "    report_to=None,\n",
    "    disable_tqdm=False,\n",
    "    prediction_loss_only=True,  # Solo calculamos loss para generaci칩n\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75ccc37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir funci칩n de m칠tricas para generaci칩n\n",
    "def compute_generation_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Calcula m칠tricas espec칤ficas para generaci칩n de secuencias.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    # Para generaci칩n, nos enfocamos principalmente en la perplejidad (calculada del loss)\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d039e977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arquitectura del modelo:\n",
      "- Tipo: XLNetLMHeadModel (para generaci칩n de secuencias)\n",
      "- Par치metros: 409,413,669\n",
      "- Vocabulario: 37 tokens\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el Trainer para generaci칩n\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_generation_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nArquitectura del modelo:\")\n",
    "print(f\"- Tipo: {type(model).__name__} (para generaci칩n de secuencias)\")\n",
    "print(f\"- Par치metros: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"- Vocabulario: {tokenizer.vocab_size} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9cf2078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando entrenamiento para generaci칩n de secuencias...\n",
      "Este modelo aprender치 a generar secuencias de prote칤nas similares a las del entrenamiento\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  8/456 09:11 < 11:26:21, 0.01 it/s, Epoch 0.05/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIniciando entrenamiento para generaci칩n de secuencias...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEste modelo aprender치 a generar secuencias de prote칤nas similares a las del entrenamiento\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\TMP_CASES\\DEV\\GIT\\ADVANCE_DRUG_DISCOVERY\\ADVANCED_DRUG_DISCOVERY\\.VENV\\lib\\site-packages\\transformers\\trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\TMP_CASES\\DEV\\GIT\\ADVANCE_DRUG_DISCOVERY\\ADVANCED_DRUG_DISCOVERY\\.VENV\\lib\\site-packages\\transformers\\trainer.py:2536\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m   2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[0;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m-> 2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2537\u001b[0m ):\n\u001b[0;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[0;32m   2540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "print(\"\\nIniciando entrenamiento para generaci칩n de secuencias...\")\n",
    "print(\"Este modelo aprender치 a generar secuencias de prote칤nas similares a las del entrenamiento\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo y el tokenizador\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Modelo de generaci칩n guardado en {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bc1885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "print(\"Evaluando el modelo...\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Resultados de evaluaci칩n: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23adff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para generar nuevas secuencias\n",
    "def generate_protein_sequence(prompt=\"\", max_new_tokens=100, temperature=0.8, do_sample=True):\n",
    "    \"\"\"\n",
    "    Genera una nueva secuencia de prote칤na.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Secuencia inicial (puede estar vac칤a)\n",
    "        max_new_tokens: N칰mero m치ximo de tokens nuevos a generar\n",
    "        temperature: Controla la aleatoriedad (m치s alto = m치s aleatorio)\n",
    "        do_sample: Si usar sampling o greedy decoding\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Si no hay prompt, usar un token especial o secuencia corta com칰n\n",
    "    if not prompt:\n",
    "        prompt = \"M\"  # Muchas prote칤nas empiezan con metionina\n",
    "    \n",
    "    # Tokenizar el prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Generar secuencia\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=do_sample,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.1\n",
    "        )\n",
    "    \n",
    "    # Decodificar la secuencia generada\n",
    "    generated_sequence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Remover el prompt original para obtener solo la parte generada\n",
    "    if prompt:\n",
    "        generated_sequence = generated_sequence[len(prompt):]\n",
    "    \n",
    "    return generated_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d039739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multiple_sequences(num_sequences=5, **generation_kwargs):\n",
    "    \"\"\"\n",
    "    Genera m칰ltiples secuencias de prote칤nas.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    for i in range(num_sequences):\n",
    "        seq = generate_protein_sequence(**generation_kwargs)\n",
    "        sequences.append(seq)\n",
    "        print(f\"Secuencia {i+1}: {seq}\")\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb06e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de generaci칩n\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EJEMPLOS DE GENERACI칍N DE SECUENCIAS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Generar secuencias sin prompt\n",
    "print(\"\\n1. Generaci칩n sin prompt inicial:\")\n",
    "generated_seqs = generate_multiple_sequences(\n",
    "    num_sequences=3,\n",
    "    max_new_tokens=80,\n",
    "    temperature=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar con diferentes temperaturas\n",
    "print(\"\\n2. Generaci칩n con diferentes temperaturas:\")\n",
    "for temp in [0.5, 0.8, 1.2]:\n",
    "    print(f\"\\nTemperatura {temp}:\")\n",
    "    seq = generate_protein_sequence(\n",
    "        prompt=\"MKT\",\n",
    "        max_new_tokens=60,\n",
    "        temperature=temp\n",
    "    )\n",
    "    print(f\"  {seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar con prompt espec칤fico\n",
    "print(\"\\n3. Generaci칩n con prompt espec칤fico:\")\n",
    "prompt = \"MKTVRQERLKSIV\"\n",
    "extended_seq = generate_protein_sequence(\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Generado: {extended_seq}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
